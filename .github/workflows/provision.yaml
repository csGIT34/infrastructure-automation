name: Infrastructure Provision

on:
  repository_dispatch:
    types: [provision]
  workflow_dispatch:
    inputs:
      repository:
        description: 'Source repository (owner/repo)'
        required: true
        type: string
      commit_sha:
        description: 'Commit SHA'
        required: true
        type: string
      yaml_url:
        description: 'Raw URL to infrastructure.yaml'
        required: true
        type: string

permissions:
  id-token: write
  contents: read

env:
  AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
  AZURE_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
  TF_STATE_STORAGE_ACCOUNT: ${{ secrets.TF_STATE_STORAGE_ACCOUNT }}
  TF_STATE_CONTAINER: "tfstate"

jobs:
  # =========================================================================
  # Job 1: Parse and resolve all patterns from multi-document YAML
  # =========================================================================
  resolve-patterns:
    runs-on: ["self-hosted", "linux"]
    outputs:
      patterns_json: ${{ steps.resolve.outputs.patterns_json }}
      execution_order: ${{ steps.resolve.outputs.execution_order }}
      document_count: ${{ steps.resolve.outputs.document_count }}
      create_count: ${{ steps.resolve.outputs.create_count }}
      destroy_count: ${{ steps.resolve.outputs.destroy_count }}
      repository: ${{ steps.request.outputs.repository }}
      repo_owner: ${{ steps.request.outputs.repo_owner }}
      repo_name: ${{ steps.request.outputs.repo_name }}
      commit_sha: ${{ steps.request.outputs.commit_sha }}
      request_id: ${{ steps.request.outputs.request_id }}

    steps:
      - name: Checkout infrastructure-automation
        uses: actions/checkout@v4

      - name: Extract request info
        id: request
        run: |
          # Handle both repository_dispatch and workflow_dispatch
          if [ "${{ github.event_name }}" == "repository_dispatch" ]; then
            REPO="${{ github.event.client_payload.repository }}"
            SHA="${{ github.event.client_payload.commit_sha }}"
            YAML_URL="${{ github.event.client_payload.yaml_url }}"
          else
            REPO="${{ inputs.repository }}"
            SHA="${{ inputs.commit_sha }}"
            YAML_URL="${{ inputs.yaml_url }}"
          fi

          # Extract owner and repo name for GitHub App token
          REPO_OWNER="${REPO%%/*}"
          REPO_NAME="${REPO##*/}"

          echo "repository=$REPO" >> $GITHUB_OUTPUT
          echo "repo_owner=$REPO_OWNER" >> $GITHUB_OUTPUT
          echo "repo_name=$REPO_NAME" >> $GITHUB_OUTPUT
          echo "commit_sha=$SHA" >> $GITHUB_OUTPUT
          echo "yaml_url=$YAML_URL" >> $GITHUB_OUTPUT
          echo "request_id=provision-${REPO//\//-}-${SHA:0:8}-$(date +%s)" >> $GITHUB_OUTPUT

      # Generate token for communicating back to the source repo
      - name: Generate GitHub App Token
        id: app-token
        uses: actions/create-github-app-token@v1
        with:
          app-id: ${{ secrets.INFRA_APP_ID }}
          private-key: ${{ secrets.INFRA_APP_PRIVATE_KEY }}
          owner: ${{ steps.request.outputs.repo_owner }}
          repositories: ${{ steps.request.outputs.repo_name }}

      # Set commit status to pending immediately
      - name: Set Commit Status - Pending
        env:
          GH_TOKEN: ${{ steps.app-token.outputs.token }}
        run: |
          gh api repos/${{ steps.request.outputs.repository }}/statuses/${{ steps.request.outputs.commit_sha }} \
            -f state=pending \
            -f target_url="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}" \
            -f description="Infrastructure provisioning in progress..." \
            -f context="infrastructure/provision"

      - name: Write infrastructure.yaml
        run: |
          # Get YAML content from payload (base64 encoded for safety)
          if [ "${{ github.event_name }}" == "repository_dispatch" ]; then
            echo "${{ github.event.client_payload.yaml_content }}" | base64 -d > infrastructure.yaml
          else
            # For manual workflow_dispatch, download from URL (requires public repo or auth)
            curl -sL "${{ steps.request.outputs.yaml_url }}" -o infrastructure.yaml
          fi
          echo "Infrastructure request from ${{ steps.request.outputs.repository }}:"
          cat infrastructure.yaml

      - name: Install Python dependencies
        run: |
          pip3 install --quiet --break-system-packages pyyaml

      - name: Resolve all patterns
        id: resolve
        run: |
          python3 << 'PYTHON_SCRIPT'
          import yaml
          import json
          import os
          import subprocess
          import sys

          with open('infrastructure.yaml', 'r') as f:
              documents = list(yaml.safe_load_all(f))
              documents = [d for d in documents if d is not None]

          if not documents:
              print("::error::No valid documents found in YAML")
              sys.exit(1)

          print(f"Found {len(documents)} document(s)")

          # Run pattern resolver with multi-json output
          result = subprocess.run(
              ['python3', 'scripts/resolve-pattern.py', 'infrastructure.yaml', '--output', 'multi-json'],
              capture_output=True,
              text=True
          )

          if result.returncode != 0:
              print(f"::error::Pattern resolution failed: {result.stderr}")
              sys.exit(1)

          resolved = json.loads(result.stdout)

          # Write individual tfvars files for each pattern
          for pattern in resolved.get('patterns', []):
              if not pattern.get('valid', False):
                  continue
              idx = pattern['index']
              tfvars = pattern.get('tfvars', {})
              with open(f'terraform.tfvars.{idx}.json', 'w') as f:
                  json.dump(tfvars, f, indent=2)
              print(f"Wrote terraform.tfvars.{idx}.json for {pattern['pattern']} ({pattern['action']})")

          # Build patterns JSON for matrix
          patterns_for_matrix = []
          for pattern in resolved.get('patterns', []):
              if not pattern.get('valid', False):
                  print(f"::warning::Skipping invalid pattern at index {pattern['index']}: {pattern.get('errors', [])}")
                  continue

              # Get the original document for metadata
              doc = documents[pattern['index']]
              metadata = doc.get('metadata', {})

              patterns_for_matrix.append({
                  'index': pattern['index'],
                  'action': pattern['action'],
                  'pattern': pattern['pattern'],
                  'state_key': pattern['state_key'],
                  'environment': metadata.get('environment', 'dev'),
                  'project': metadata.get('project', 'unknown'),
                  'business_unit': metadata.get('business_unit', 'default'),
                  'name': doc.get('config', {}).get('name', pattern['pattern'])
              })

          execution_order = resolved.get('execution_order', list(range(len(patterns_for_matrix))))

          # Output for subsequent jobs
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"patterns_json={json.dumps(patterns_for_matrix)}\n")
              f.write(f"execution_order={json.dumps(execution_order)}\n")
              f.write(f"document_count={resolved.get('document_count', len(documents))}\n")
              f.write(f"create_count={resolved.get('create_count', 0)}\n")
              f.write(f"destroy_count={resolved.get('destroy_count', 0)}\n")

          print(f"Resolved {len(patterns_for_matrix)} valid patterns")
          print(f"Execution order: {execution_order}")
          print(f"Create: {resolved.get('create_count', 0)}, Destroy: {resolved.get('destroy_count', 0)}")
          PYTHON_SCRIPT

      - name: Upload tfvars artifacts
        uses: actions/upload-artifact@v4
        with:
          name: tfvars-files
          path: terraform.tfvars.*.json
          retention-days: 1

  # =========================================================================
  # Job 2: Process each pattern sequentially using matrix
  # =========================================================================
  provision-pattern:
    needs: resolve-patterns
    runs-on: ["self-hosted", "linux"]
    if: ${{ needs.resolve-patterns.outputs.patterns_json != '[]' }}
    strategy:
      matrix:
        pattern: ${{ fromJson(needs.resolve-patterns.outputs.patterns_json) }}
      max-parallel: 1  # Sequential execution for proper ordering
      fail-fast: false  # Continue on failure to process remaining patterns

    outputs:
      result: ${{ steps.result.outputs.status }}

    steps:
      - name: Checkout infrastructure-automation
        uses: actions/checkout@v4

      - name: Download tfvars artifacts
        uses: actions/download-artifact@v4
        with:
          name: tfvars-files

      - name: Display pattern info
        run: |
          echo "Processing pattern ${{ matrix.pattern.index }}: ${{ matrix.pattern.pattern }}"
          echo "  Action: ${{ matrix.pattern.action }}"
          echo "  Environment: ${{ matrix.pattern.environment }}"
          echo "  Project: ${{ matrix.pattern.project }}"
          echo "  State Key: ${{ matrix.pattern.state_key }}"

      - name: Azure Login
        uses: azure/login@v1
        with:
          client-id: ${{ secrets[format('AZURE_CLIENT_ID_{0}', matrix.pattern.environment)] }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Setup Terraform workspace
        run: |
          PATTERN="${{ matrix.pattern.pattern }}"
          INDEX="${{ matrix.pattern.index }}"

          # Preserve directory structure so ../../modules/ paths work
          mkdir -p terraform-workspace/terraform/patterns
          cp -r "terraform/patterns/$PATTERN" "terraform-workspace/terraform/patterns/$PATTERN"
          cp -r terraform/modules terraform-workspace/terraform/
          cp "terraform.tfvars.${INDEX}.json" "terraform-workspace/terraform/patterns/$PATTERN/terraform.tfvars.json"

      - name: Terraform Init
        working-directory: terraform-workspace/terraform/patterns/${{ matrix.pattern.pattern }}
        env:
          ARM_USE_OIDC: true
          ARM_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
          ARM_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          ARM_CLIENT_ID: ${{ secrets[format('AZURE_CLIENT_ID_{0}', matrix.pattern.environment)] }}
        run: |
          terraform init -upgrade \
            -backend-config="storage_account_name=${{ env.TF_STATE_STORAGE_ACCOUNT }}" \
            -backend-config="container_name=${{ env.TF_STATE_CONTAINER }}" \
            -backend-config="key=${{ matrix.pattern.state_key }}" \
            -backend-config="use_oidc=true" \
            -backend-config="use_azuread_auth=true"

      - name: Terraform Plan
        working-directory: terraform-workspace/terraform/patterns/${{ matrix.pattern.pattern }}
        env:
          ARM_USE_OIDC: true
          ARM_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
          ARM_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          ARM_CLIENT_ID: ${{ secrets[format('AZURE_CLIENT_ID_{0}', matrix.pattern.environment)] }}
        run: |
          # Add -destroy flag for destroy actions
          if [ "${{ matrix.pattern.action }}" == "destroy" ]; then
            echo "ðŸ—‘ï¸ Planning DESTROY for ${{ matrix.pattern.pattern }}"
            terraform plan -destroy \
              -var-file=terraform.tfvars.json \
              -out=tfplan \
              -no-color
          else
            echo "âœ¨ Planning CREATE for ${{ matrix.pattern.pattern }}"
            terraform plan \
              -var-file=terraform.tfvars.json \
              -out=tfplan \
              -no-color
          fi

      - name: Terraform Apply
        working-directory: terraform-workspace/terraform/patterns/${{ matrix.pattern.pattern }}
        env:
          ARM_USE_OIDC: true
          ARM_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
          ARM_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          ARM_CLIENT_ID: ${{ secrets[format('AZURE_CLIENT_ID_{0}', matrix.pattern.environment)] }}
        run: |
          terraform apply -auto-approve tfplan

      - name: Capture Terraform Outputs
        id: outputs
        if: matrix.pattern.action == 'create'
        working-directory: terraform-workspace/terraform/patterns/${{ matrix.pattern.pattern }}
        run: |
          terraform output -json > /tmp/tf-outputs-${{ matrix.pattern.index }}.json
          echo "Terraform outputs for pattern ${{ matrix.pattern.index }}:"
          cat /tmp/tf-outputs-${{ matrix.pattern.index }}.json

      - name: Upload outputs artifact
        if: matrix.pattern.action == 'create'
        uses: actions/upload-artifact@v4
        with:
          name: tf-outputs-${{ matrix.pattern.index }}
          path: /tmp/tf-outputs-${{ matrix.pattern.index }}.json
          retention-days: 1

      - name: Set result status
        id: result
        if: always()
        run: |
          if [ "${{ job.status }}" == "success" ]; then
            echo "status=success" >> $GITHUB_OUTPUT
          else
            echo "status=failure" >> $GITHUB_OUTPUT
          fi

  # =========================================================================
  # Job 3: Report aggregated status to source repository
  # =========================================================================
  report-status:
    needs: [resolve-patterns, provision-pattern]
    if: always()
    runs-on: ["self-hosted", "linux"]

    steps:
      - name: Checkout infrastructure-automation
        uses: actions/checkout@v4

      - name: Generate GitHub App Token
        id: app-token
        uses: actions/create-github-app-token@v1
        with:
          app-id: ${{ secrets.INFRA_APP_ID }}
          private-key: ${{ secrets.INFRA_APP_PRIVATE_KEY }}
          owner: ${{ needs.resolve-patterns.outputs.repo_owner }}
          repositories: ${{ needs.resolve-patterns.outputs.repo_name }}

      - name: Download all output artifacts
        uses: actions/download-artifact@v4
        with:
          path: outputs
        continue-on-error: true

      - name: Aggregate results and create report
        id: report
        run: |
          python3 << 'PYTHON_SCRIPT'
          import json
          import os
          import glob

          # Get job status
          provision_result = "${{ needs.provision-pattern.result }}"
          resolve_result = "${{ needs.resolve-patterns.result }}"

          # Get pattern info
          patterns_json = '${{ needs.resolve-patterns.outputs.patterns_json }}'
          patterns = json.loads(patterns_json) if patterns_json else []

          document_count = int("${{ needs.resolve-patterns.outputs.document_count }}" or "0")
          create_count = int("${{ needs.resolve-patterns.outputs.create_count }}" or "0")
          destroy_count = int("${{ needs.resolve-patterns.outputs.destroy_count }}" or "0")

          # Determine overall status
          if resolve_result != 'success':
              overall_status = 'failure'
              status_emoji = 'âŒ'
              status_text = 'Resolution Failed'
          elif provision_result == 'success':
              overall_status = 'success'
              status_emoji = 'âœ…'
              status_text = 'All Patterns Succeeded'
          elif provision_result == 'failure':
              # Check if partial success (some patterns succeeded)
              overall_status = 'failure'
              status_emoji = 'âš ï¸'
              status_text = 'Partial Failure'
          else:
              overall_status = 'failure'
              status_emoji = 'âŒ'
              status_text = 'Provisioning Failed'

          # Build issue body - use string concat to avoid YAML parser issues with | and {
          issue_body = f"## {status_emoji} Infrastructure Provisioning Results\n\n"
          issue_body += f"### Overall Status: {status_text}\n\n"
          issue_body += "| Property | Value |\n"
          issue_body += "|----------|-------|\n"
          issue_body += f"| Documents | {document_count} |\n"
          issue_body += f"| Create Actions | {create_count} |\n"
          issue_body += f"| Destroy Actions | {destroy_count} |\n"
          issue_body += "| Commit | `${{ needs.resolve-patterns.outputs.commit_sha }}` |\n"
          issue_body += "| Workflow Run | [View Details](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}) |\n\n"
          issue_body += "### Pattern Results\n\n"
          issue_body += "| Doc | Action | Pattern | Name | Status |\n"
          issue_body += "|-----|--------|---------|------|--------|\n"

          # Add pattern results
          for pattern in patterns:
              action_icon = "ðŸ—‘ï¸" if pattern['action'] == 'destroy' else "âœ¨"
              # We'll mark all as success if the job succeeded, otherwise unknown
              # In a real scenario, you'd track individual pattern results
              status_icon = "âœ…" if provision_result == 'success' else "âš ï¸"
              issue_body += f"| {pattern['index']} | {action_icon} {pattern['action']} | `{pattern['pattern']}` | `{pattern['name']}` | {status_icon} |\n"

          issue_body += "\n"

          # Add outputs section for create actions
          output_files = glob.glob('outputs/tf-outputs-*/tf-outputs-*.json')
          if output_files and provision_result == 'success':
              issue_body += "### Resource Outputs\n\n"
              for output_file in sorted(output_files):
                  try:
                      with open(output_file) as f:
                          outputs = json.load(f)

                      # Extract index from filename
                      idx = output_file.split('-')[-1].replace('.json', '')
                      pattern_info = next((p for p in patterns if str(p['index']) == idx), None)

                      if pattern_info:
                          issue_body += f"#### Document {idx}: {pattern_info['pattern']}\n\n"
                          issue_body += "| Output | Value |\n"
                          issue_body += "|--------|-------|\n"

                          for key, value in outputs.items():
                              val = value.get('value', '')
                              sensitive = value.get('sensitive', False)
                              if sensitive:
                                  issue_body += f"| {key} | *(sensitive - see Key Vault)* |\n"
                              elif isinstance(val, dict):
                                  for k, v in val.items():
                                      issue_body += f"| {key}.{k} | `{v}` |\n"
                              elif isinstance(val, list):
                                  issue_body += f"| {key} | `{', '.join(str(v) for v in val)}` |\n"
                              else:
                                  issue_body += f"| {key} | `{val}` |\n"
                          issue_body += "\n"
                  except Exception as e:
                      print(f"Warning: Could not parse {output_file}: {e}")

          # Add next steps - use string concat to avoid YAML parser issues
          if overall_status == 'success':
              issue_body += "### Next Steps\n\n"
              issue_body += "1. **Request access** - Ask your team lead to add you to the appropriate security group\n"
              issue_body += "2. **Access secrets** - Once added, retrieve secrets from Key Vault\n\n"
              issue_body += "### Questions or Issues?\n\n"
              issue_body += "If you encounter problems, create an issue in the infrastructure-automation repository.\n"
          else:
              issue_body += "### Troubleshooting\n\n"
              issue_body += "1. **View the error** - Check the workflow run for detailed error messages\n"
              issue_body += "2. **Fix the issue** - Update your infrastructure.yaml based on the error\n"
              issue_body += "3. **Retry** - Commit and push to trigger a new provisioning attempt\n\n"
              issue_body += "### Common Issues\n\n"
              issue_body += "- Invalid pattern configuration - Check that all required fields are present\n"
              issue_body += "- Naming conflicts - Resource names must be unique within Azure\n"
              issue_body += "- Permission errors - The service principal may not have required permissions\n"
              issue_body += "- Quota limits - Your subscription may have hit resource limits\n\n"
              issue_body += "### Need Help?\n\n"
              issue_body += "Create an issue in the infrastructure-automation repository.\n"

          issue_body += "\n---\n"
          issue_body += "*Provisioned by Infrastructure Platform*\n"

          # Write outputs
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"overall_status={overall_status}\n")
              f.write(f"status_text={status_text}\n")

          # Write issue body to file for the next step
          with open('/tmp/issue_body.md', 'w') as f:
              f.write(issue_body)

          print(f"Overall status: {overall_status}")
          print(f"Status text: {status_text}")
          PYTHON_SCRIPT

      - name: Set Commit Status
        env:
          GH_TOKEN: ${{ steps.app-token.outputs.token }}
        run: |
          STATUS="${{ steps.report.outputs.overall_status }}"
          STATUS_TEXT="${{ steps.report.outputs.status_text }}"

          gh api repos/${{ needs.resolve-patterns.outputs.repository }}/statuses/${{ needs.resolve-patterns.outputs.commit_sha }} \
            -f state="$STATUS" \
            -f target_url="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}" \
            -f description="$STATUS_TEXT" \
            -f context="infrastructure/provision"

      - name: Create Issue in Source Repo
        env:
          GH_TOKEN: ${{ steps.app-token.outputs.token }}
        run: |
          STATUS="${{ steps.report.outputs.overall_status }}"

          if [ "$STATUS" == "success" ]; then
            TITLE="âœ… Infrastructure Provisioned (${{ needs.resolve-patterns.outputs.create_count }} created, ${{ needs.resolve-patterns.outputs.destroy_count }} destroyed)"
          else
            TITLE="âŒ Infrastructure Provisioning Failed"
          fi

          ISSUE_BODY=$(cat /tmp/issue_body.md)

          # Create the issue (ignore label errors if label doesn't exist)
          gh issue create \
            --repo "${{ needs.resolve-patterns.outputs.repository }}" \
            --title "$TITLE" \
            --body "$ISSUE_BODY" \
            --label "infrastructure" || gh issue create \
            --repo "${{ needs.resolve-patterns.outputs.repository }}" \
            --title "$TITLE" \
            --body "$ISSUE_BODY"

      - name: Create Job Summary
        run: |
          cat /tmp/issue_body.md >> $GITHUB_STEP_SUMMARY
