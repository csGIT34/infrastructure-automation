name: Infrastructure Provision Worker

on:
    workflow_call:
        inputs:
            queue_name:
                required: true
                type: string
            environment:
                required: true
                type: string
            runner_labels:
                required: true
                type: string
            max_parallel:
                required: false
                type: number
                default: 10

permissions:
    id-token: write
    contents: read

env:
    AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
    AZURE_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
    SERVICEBUS_NAMESPACE: ${{ secrets.SERVICEBUS_NAMESPACE }}
    COSMOS_ENDPOINT: ${{ secrets.COSMOS_ENDPOINT }}
    COSMOS_DATABASE: "infrastructure-db"
    TF_STATE_STORAGE_ACCOUNT: ${{ secrets.TF_STATE_STORAGE_ACCOUNT }}
    TF_STATE_CONTAINER: "tfstate"

jobs:
    process-requests:
        runs-on: ${{ fromJSON(inputs.runner_labels) }}
        strategy:
            max-parallel: ${{ inputs.max_parallel }}
            matrix:
                worker: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

        environment: ${{ inputs.environment == 'prod' && 'production' || '' }}

        steps:
            - name: Checkout repository
              uses: actions/checkout@v4

            - name: Install Python dependencies
              run: |
                  pip3 install azure-servicebus azure-identity azure-cosmos pyyaml

            - name: Azure Login
              uses: azure/login@v1
              with:
                  client-id: ${{ secrets[format('AZURE_CLIENT_ID_{0}', inputs.environment)] }}
                  tenant-id: ${{ secrets.AZURE_TENANT_ID }}
                  subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

            - name: Process infrastructure request
              id: process
              env:
                  QUEUE_NAME: ${{ inputs.queue_name }}
                  ENVIRONMENT: ${{ inputs.environment }}
                  GITHUB_RUN_ID: ${{ github.run_id }}
                  GITHUB_RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
                  # Terraform OIDC authentication
                  ARM_USE_OIDC: true
                  ARM_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
                  ARM_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
                  ARM_CLIENT_ID: ${{ secrets[format('AZURE_CLIENT_ID_{0}', inputs.environment)] }}
              run: |
                  python3 << 'PYTHON_SCRIPT'
                  import os
                  import sys
                  import json
                  import yaml
                  import subprocess
                  from datetime import datetime
                  from azure.servicebus import ServiceBusClient
                  from azure.identity import DefaultAzureCredential
                  from azure.cosmos import CosmosClient

                  # Configuration from environment
                  SERVICEBUS_NAMESPACE = os.environ['SERVICEBUS_NAMESPACE']
                  COSMOS_ENDPOINT = os.environ['COSMOS_ENDPOINT']
                  QUEUE_NAME = os.environ['QUEUE_NAME']
                  ENVIRONMENT = os.environ['ENVIRONMENT']
                  GITHUB_RUN_ID = os.environ['GITHUB_RUN_ID']
                  GITHUB_RUN_URL = os.environ['GITHUB_RUN_URL']
                  TF_STATE_STORAGE_ACCOUNT = os.environ['TF_STATE_STORAGE_ACCOUNT']
                  TF_STATE_CONTAINER = os.environ['TF_STATE_CONTAINER']

                  credential = DefaultAzureCredential()

                  # Initialize Service Bus client
                  servicebus_client = ServiceBusClient(
                      f"{SERVICEBUS_NAMESPACE}.servicebus.windows.net",
                      credential=credential
                  )

                  # Initialize Cosmos DB client
                  cosmos_client = CosmosClient(COSMOS_ENDPOINT, credential=credential)
                  database = cosmos_client.get_database_client("infrastructure-db")
                  container = database.get_container_client("requests")

                  def update_cosmos_status(request_id, status, extra_fields=None):
                      """Update request status in Cosmos DB, preserving existing fields"""
                      try:
                          # Read existing record first to preserve original fields
                          try:
                              existing = container.read_item(item=request_id, partition_key=request_id)
                          except Exception:
                              existing = {'id': request_id, 'requestId': request_id}

                          # Update with new values
                          existing['status'] = status
                          existing['updated_at'] = datetime.utcnow().isoformat()
                          if extra_fields:
                              existing.update(extra_fields)

                          container.upsert_item(body=existing)
                          print(f"Updated request {request_id} to '{status}'")
                      except Exception as e:
                          print(f"Warning: Failed to update Cosmos DB: {e}")

                  def run_terraform(config, request_id):
                      """Run Terraform init, plan, and apply"""
                      # Create workspace directory
                      os.makedirs('terraform-workspace', exist_ok=True)

                      # Write config file
                      with open('terraform-workspace/config.yaml', 'w') as f:
                          yaml.dump(config, f)

                      # Copy Terraform files
                      subprocess.run(['cp', '-r', 'terraform/catalog', 'terraform-workspace/'], check=True)
                      subprocess.run(['cp', '-r', 'terraform/modules', 'terraform-workspace/'], check=True)

                      # Extract metadata for state key
                      metadata = config.get('metadata', {})
                      project_name = metadata.get('project_name', 'unknown')
                      environment = metadata.get('environment', 'dev')
                      business_unit = metadata.get('business_unit', 'default')
                      state_key = f"{business_unit}/{environment}/{project_name}/terraform.tfstate"

                      work_dir = 'terraform-workspace/catalog'

                      # Terraform init
                      print(f"Running terraform init with state key: {state_key}")
                      init_result = subprocess.run(
                          [
                              'terraform', 'init',
                              f'-backend-config=storage_account_name={TF_STATE_STORAGE_ACCOUNT}',
                              f'-backend-config=container_name={TF_STATE_CONTAINER}',
                              f'-backend-config=key={state_key}',
                              '-backend-config=use_oidc=true',
                              '-backend-config=use_azuread_auth=true'
                          ],
                          cwd=work_dir,
                          capture_output=True,
                          text=True
                      )
                      if init_result.returncode != 0:
                          raise Exception(f"Terraform init failed: {init_result.stderr}")
                      print(init_result.stdout)

                      # Terraform plan
                      print("Running terraform plan")
                      plan_result = subprocess.run(
                          [
                              'terraform', 'plan',
                              '-var=config_file=../config.yaml',
                              '-out=tfplan',
                              '-no-color'
                          ],
                          cwd=work_dir,
                          capture_output=True,
                          text=True
                      )
                      if plan_result.returncode != 0:
                          raise Exception(f"Terraform plan failed: {plan_result.stderr}")
                      print(plan_result.stdout)

                      # Terraform apply
                      print("Running terraform apply")
                      apply_result = subprocess.run(
                          ['terraform', 'apply', '-auto-approve', 'tfplan'],
                          cwd=work_dir,
                          capture_output=True,
                          text=True
                      )
                      if apply_result.returncode != 0:
                          raise Exception(f"Terraform apply failed: {apply_result.stderr}")
                      print(apply_result.stdout)

                      # Capture outputs
                      output_result = subprocess.run(
                          ['terraform', 'output', '-json'],
                          cwd=work_dir,
                          capture_output=True,
                          text=True
                      )
                      outputs = json.loads(output_result.stdout) if output_result.returncode == 0 else {}

                      return outputs

                  # Main processing logic
                  receiver = servicebus_client.get_queue_receiver(QUEUE_NAME, max_wait_time=5)

                  try:
                      # Receive a single message
                      messages = receiver.receive_messages(max_message_count=1, max_wait_time=5)

                      if not messages:
                          print("No messages in queue")
                          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                              f.write("has_message=false\n")
                          sys.exit(0)

                      message = messages[0]

                      try:
                          # Parse message body
                          body = json.loads(str(message))
                          request_id = body['request_id']
                          yaml_content = body['yaml_content']
                          config = yaml.safe_load(yaml_content)

                          # Extract metadata for tracking
                          metadata = config.get('metadata', {})
                          project_name = metadata.get('project_name', 'unknown')
                          environment = metadata.get('environment', 'dev')
                          requester_email = body.get('requester_email', metadata.get('owner_email', 'unknown'))

                          print(f"Processing request: {request_id}")
                          print(f"  Project: {project_name}, Environment: {environment}")

                          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                              f.write("has_message=true\n")
                              f.write(f"request_id={request_id}\n")

                          # Update status to processing
                          update_cosmos_status(request_id, 'processing', {
                              'project_name': project_name,
                              'environment': environment,
                              'requester_email': requester_email,
                              'github_run_id': GITHUB_RUN_ID,
                              'github_run_url': GITHUB_RUN_URL
                          })

                          # Run Terraform
                          outputs = run_terraform(config, request_id)

                          # Update status to completed with full deployment state
                          update_cosmos_status(request_id, 'completed', {
                              'project_name': project_name,
                              'environment': environment,
                              'requester_email': requester_email,
                              'yaml_content': yaml_content,
                              'resources': config.get('resources', []),
                              'completed_at': datetime.utcnow().isoformat(),
                              'terraform_outputs': outputs
                          })

                          # Complete the message (remove from queue)
                          receiver.complete_message(message)
                          print(f"Request {request_id} completed successfully")

                      except Exception as e:
                          print(f"Error processing request: {e}")

                          # Update status to failed
                          if 'request_id' in dir():
                              failed_fields = {'error_message': str(e)}
                              if 'project_name' in dir():
                                  failed_fields['project_name'] = project_name
                                  failed_fields['environment'] = environment
                              update_cosmos_status(request_id, 'failed', failed_fields)

                          # Abandon the message (return to queue for retry)
                          receiver.abandon_message(message)
                          print("Message abandoned for retry")
                          sys.exit(1)

                  finally:
                      receiver.close()
                      servicebus_client.close()

                  PYTHON_SCRIPT
